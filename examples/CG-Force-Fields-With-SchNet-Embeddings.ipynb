{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Coarse-Grained Force Field with Embeddings from SchNet\n",
    "\n",
    "In this tutorial we build upon the standard CGnet [1] architecture by additionally adding a SchNet [2] layer and, thereby, embedded properties of the coarse-grained beads. We again utilize the subsampled alanine dipeptide dataset, which should _not_ be used for research results.\n",
    "\n",
    "If you haven't done the Training-A-Coarse-Grained-Force-Field tutorial, we recommend going through that notebook first, since we breeze through analogous calculations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, setup, and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import mdtraj as md\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from cgnet.feature import (MoleculeDataset, GeometryStatistics,\n",
    "                           GeometryFeature, ShiftedSoftplus,\n",
    "                           CGBeadEmbedding, SchnetFeature,\n",
    "                           FeatureCombiner, LinearLayer)\n",
    "\n",
    "from cgnet.network import (HarmonicLayer, CGnet, ForceLoss,\n",
    "                           lipschitz_projection, Simulation)\n",
    "\n",
    "from cgnet.molecule import CGMolecule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# We specify the cpu device here, but a gpu works too!\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data: if you want to run the notebook really quickly, we suggest using the second set of coordinates and forces for a meaningless result but quick execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.load('./data/ala2_coordinates.npy')\n",
    "forces = np.load('./data/ala2_forces.npy')\n",
    "\n",
    "# coords = np.load('./data/ala2_coordinates.npy')[::10]\n",
    "# forces = np.load('./data/ala2_forces.npy')[::10]\n",
    "\n",
    "print(\"Coordinates size: {}\".format(coords.shape))\n",
    "print(\"Force: {}\".format(forces.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous example, we not only need coordinates and forces, but also _embeddings_. Here we're going to go with the SchNet convention [2] of embedding the atomic number of the element corresponding to the bead. Since our beads are the backbone C-N-C-C-N, we embed the properties (6, 7, 6, 6, 7). We'll create the embeddings ourselves as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.tile([6, 7, 6, 6, 7], [coords.shape[0], 1])\n",
    "print(\"Embeddings size: {}\".format(embeddings.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we instantiate our `MoleculeDataset` with emeddings as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ala_data = MoleculeDataset(coords, forces, embeddings)\n",
    "print(\"Dataset length: {}\".format(len(ala_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering statistics and making our GeometryFeature\n",
    "\n",
    "Ultimately, our network is going to have a GeometryFeature, like before, except this time stacked with a SchnetFeature. So we still need to grab the statistics for our priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = GeometryStatistics(coords, backbone_inds='all')\n",
    "\n",
    "bond_list, bond_keys = stats.get_prior_statistics(features='Bonds', as_list=True)\n",
    "bond_indices = stats.return_indices('Bonds')\n",
    "\n",
    "angle_list, angle_keys = stats.get_prior_statistics(features='Angles', as_list=True)\n",
    "angle_indices = stats.return_indices('Angles')\n",
    "\n",
    "print(\"We have {} backbone beads, {} bonds, and {} angles.\".format(\n",
    "                        coords.shape[1], len(bond_list), len(angle_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats, _ = stats.get_prior_statistics(as_list=True)\n",
    "zscores, _ = stats.get_zscore_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_beads = coords.shape[1]\n",
    "geometry_feature = GeometryFeature(n_beads=n_beads,\n",
    "                                   device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying hyperparameters\n",
    "\n",
    "We specify all the hyperparameters now, since we'll need some of them to build our `SchnetFeature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "n_layers = 5\n",
    "n_nodes = 128\n",
    "activation = ShiftedSoftplus()\n",
    "batch_size = 512\n",
    "learning_rate = 3e-4\n",
    "rate_decay = 0.3\n",
    "lipschitz_strength = 4.0\n",
    "\n",
    "# schnet-specific parameters\n",
    "n_embeddings = 10\n",
    "n_gaussians = 50\n",
    "n_interaction_blocks = 5\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "save_model = False\n",
    "directory = '.' # to save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our SchnetFeature\n",
    "\n",
    "We first need to make a `CGBeadEmbedding`, which we then pass to the `SchnetFeature`. We set `calculate_geometry` to `False` because we are going to be stacking this with a `GeometryFeature`, which handles the geometry stuff for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = CGBeadEmbedding(n_embeddings = n_embeddings,\n",
    "                                  embedding_dim = n_nodes)\n",
    "\n",
    "schnet_feature = SchnetFeature(feature_size = n_nodes,\n",
    "                               embedding_layer = embedding_layer,\n",
    "                               n_interaction_blocks = n_interaction_blocks,\n",
    "                               calculate_geometry = False,\n",
    "                               n_beads = n_beads,\n",
    "                               neighbor_cutoff = None,\n",
    "                               n_gaussians = n_gaussians,\n",
    "                               device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Geometry and SchnetFeatures\n",
    "\n",
    "We use the `FeatureCombiner` to stack our `GeometryFeature` and our `SchnetFeature`. We just need to tell our `FeatureCombiner` which integer indices correspond to distance features. The `FeatureCombiner` is ultimately the feature we will feed into our `CGnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_feature_indices = stats.return_indices('Distances')\n",
    "\n",
    "layer_list = [geometry_feature, schnet_feature]\n",
    "\n",
    "feature_combiner = FeatureCombiner(layer_list,\n",
    "                    distance_indices=distance_feature_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the CGnet and training tools\n",
    "\n",
    "Assemble the layers and priors, and then feed those and the `FeatureCombiner` into a `CGnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = LinearLayer(n_nodes,\n",
    "                     n_nodes,\n",
    "                     activation=activation)\n",
    "\n",
    "for _ in range(n_layers - 1):\n",
    "    layers += LinearLayer(n_nodes,\n",
    "                          n_nodes,\n",
    "                          activation=activation)\n",
    "\n",
    "# The last layer produces a single value\n",
    "layers += LinearLayer(n_nodes, 1, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors  = [HarmonicLayer(bond_indices, bond_list)]\n",
    "priors += [HarmonicLayer(angle_indices, angle_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ala2_net = CGnet(layers, ForceLoss(),\n",
    "                 feature=feature_combiner,\n",
    "                 priors=priors).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(ala_data, sampler=RandomSampler(ala_data),\n",
    "                         batch_size=batch_size)\n",
    "optimizer = torch.optim.Adam(ala2_net.parameters(),\n",
    "                             lr=learning_rate)\n",
    "scheduler = MultiStepLR(optimizer,milestones=[10,20,30,40,50],\n",
    "                        gamma=rate_decay)\n",
    "epochal_train_losses = []\n",
    "epochal_test_losses  = []\n",
    "verbose = True\n",
    "\n",
    "# printout settings\n",
    "batch_freq = 500\n",
    "epoch_freq = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!\n",
    "\n",
    "Note that we do not use a test set, so this is just for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    train_loss = 0.00\n",
    "    test_loss = 0.00\n",
    "    n = 0\n",
    "    for num, batch in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        coord, force, embedding_property = batch\n",
    "\n",
    "        \n",
    "        energy, pred_force = ala2_net.forward(coord,\n",
    "                                embedding_property=embedding_property)\n",
    "        batch_loss = ala2_net.criterion(pred_force, force)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # perform L2 lipschitz check and projection\n",
    "        lipschitz_projection(ala2_net, strength=lipschitz_strength)\n",
    "        if verbose:\n",
    "            if (num+1) % batch_freq == 0:\n",
    "                print(\n",
    "                    \"Batch: {: <5} Train: {: <20} Test: {: <20}\".format(\n",
    "                        num+1, batch_loss, test_loss)\n",
    "                )\n",
    "        train_loss += batch_loss.detach().cpu()\n",
    "        n += 1\n",
    "\n",
    "    train_loss /= n\n",
    "    if verbose:\n",
    "        if epoch % epoch_freq == 0:\n",
    "            print(\n",
    "                \"Epoch: {: <5} Train: {: <20} Test: {: <20}\".format(\n",
    "    epoch, train_loss, test_loss))\n",
    "    epochal_train_losses.append(train_loss)\n",
    "    scheduler.step()\n",
    "    \n",
    "if save_model:\n",
    "    torch.save(ala2_net,\"{}/ala2_cgschnet.pt\".format(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.arange(0,len(epochal_train_losses),1),\n",
    "         epochal_train_losses, label='Training Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(np.arange(1,5))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the system\n",
    "\n",
    "To simulate a system with a `SchnetFeature`, we need to provide the `Simulation` with embeddings.\n",
    "\n",
    "Simulations with `SchnetFeature`s tend to be _slow_. If you haven't switched your device to a GPU, we recommend the second set of parameters for a meaningless result but quickly executable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = 1000\n",
    "n_timesteps = 1000\n",
    "save_interval = 10\n",
    "\n",
    "# n_sims = 10\n",
    "# n_timesteps = 1000\n",
    "# save_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_coords = np.concatenate([coords[i].reshape(-1,5,3)\n",
    "                                 for i in np.arange(0, coords.shape[0],\n",
    "                                                    coords.shape[0]//n_sims)],\n",
    "                                                    axis=0)\n",
    "initial_coords = torch.tensor(initial_coords, requires_grad=True)\n",
    "sim_embeddings = torch.tensor(embeddings[:n_sims])\n",
    "\n",
    "print(\"Produced {} initial coordinates.\".format(len(initial_coords)))\n",
    "\n",
    "sim = Simulation(ala2_net, initial_coords, sim_embeddings, length=n_timesteps,\n",
    "                 save_interval=save_interval, beta=stats.beta,\n",
    "                 verbose=True, save_potential=True)\n",
    "\n",
    "traj = sim.simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the simulation output\n",
    "\n",
    "Here, we just copy the code from the previous tutorial to show the same example visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['C', 'N', 'CA', 'C', 'N']\n",
    "resseq = [1, 2, 2, 2, 3]\n",
    "resmap = {1: 'ACE', 2: 'ALA', 3: 'NME'}\n",
    "\n",
    "ala2_cg = CGMolecule(names=names, resseq=resseq, resmap=resmap,\n",
    "                          bonds='standard')\n",
    "\n",
    "ala2_traj = ala2_cg.make_trajectory(coords)\n",
    "ala2_simulated_traj = ala2_cg.make_trajectory(np.concatenate(traj, axis=0))\n",
    "\n",
    "_, phi = md.compute_phi(ala2_traj)\n",
    "_, psi = md.compute_psi(ala2_traj)\n",
    "\n",
    "_, sim_phi = md.compute_phi(ala2_simulated_traj)\n",
    "_, sim_psi = md.compute_psi(ala2_simulated_traj)\n",
    "\n",
    "pot, _ = ala2_net.forward(torch.tensor(coords, requires_grad=True),\n",
    "                          torch.tensor(embeddings))\n",
    "pot = pot.detach().numpy()\n",
    "pot = pot - np.min(pot)\n",
    "\n",
    "sim_pot = np.concatenate(sim.simulated_potential, axis=0)\n",
    "sim_pot = sim_pot - np.min(sim_pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(8,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(phi.reshape(-1), psi.reshape(-1),\n",
    "            c=pot.flatten(),\n",
    "            cmap=plt.get_cmap(\"viridis\"),alpha=0.5,s=0.5)\n",
    "plt.xlabel(r'$\\phi$',fontsize=16)\n",
    "plt.ylabel(r'$\\psi$',fontsize=16)\n",
    "plt.xlim(-np.pi, np.pi)\n",
    "plt.ylim(-np.pi, np.pi)\n",
    "plt.title(r'Original all-atom trajectory')\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_title(r'$U\\left(\\frac{kcal}{mol}\\right)$')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(sim_phi.reshape(-1), sim_psi.reshape(-1),\n",
    "            c=sim_pot.flatten(),\n",
    "            cmap=plt.get_cmap(\"viridis\"),alpha=0.5,s=0.5)\n",
    "plt.xlabel(r'$\\phi$',fontsize=16)\n",
    "plt.ylabel(r'$\\psi$',fontsize=16)\n",
    "plt.xlim(-np.pi, np.pi)\n",
    "plt.ylim(-np.pi, np.pi)\n",
    "plt.title('Simulated CG trajectory')\n",
    "clb=plt.colorbar()\n",
    "clb.ax.set_title(r'$U\\left(\\frac{kcal}{mol}\\right)$')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramachandran(phi, psi, bins=60, cmap=plt.cm.magma):\n",
    "    edges = np.array([[-np.pi, np.pi], [-np.pi, np.pi]])\n",
    "    counts, _, _ = np.histogram2d(psi.reshape(-1),\n",
    "                                  phi.reshape(-1),\n",
    "                                  bins=bins,\n",
    "                                  range=edges)\n",
    "    populations = counts / np.sum(counts)\n",
    "    \n",
    "    # compute energies for only non-zero entries\n",
    "    # 1/beta is approximately 0.6 kcal/mol at 300 K\n",
    "    energies = -0.6*np.log(populations,\n",
    "                           out=np.zeros_like(populations),\n",
    "                           where=(populations > 0))\n",
    "    \n",
    "    # make the lowest energy slightly above zero\n",
    "    energies = np.where(energies,\n",
    "                        energies-np.min(energies[np.nonzero(energies)]) + 1e-6,\n",
    "                        0)\n",
    "    \n",
    "    # mask the zero values from the colormap\n",
    "    zvals_masked = np.ma.masked_where(energies == 0, energies)\n",
    "\n",
    "    cmap.set_bad(color='white')\n",
    "    img = plt.imshow(zvals_masked, interpolation='nearest', cmap = cmap)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.xticks([-0.5, bins/2, bins], \n",
    "               [r'$-\\pi$', r'$0$', r'$\\pi$'])\n",
    "\n",
    "    plt.yticks([-0.5, bins/2, bins],\n",
    "               [r'$-\\pi$', r'$0$', r'$\\pi$'])\n",
    "    \n",
    "    plt.xlabel(r'$\\phi$',fontsize=16)\n",
    "    plt.ylabel(r'$\\psi$',fontsize=16)\n",
    "    \n",
    "    cb=plt.colorbar()\n",
    "    cb.ax.set_title(r'$\\tilde{F}\\left(\\frac{kcal}{mol}\\right)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(8,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plot_ramachandran(phi, psi)\n",
    "plt.title('Original all-atom trajectory')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plot_ramachandran(sim_phi, sim_psi)\n",
    "plt.title('Simulated CG trajectory')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *References*\n",
    "\n",
    "[1] Wang, J., Olsson, S., Wehmeyer, C., Pérez, A., Charron, N. E., de Fabritiis, G., Noé, F., and Clementi, C. (2019). Machine Learning of Coarse-Grained Molecular Dynamics Force Fields. _ACS Central Science._ https://doi.org/10.1021/acscentsci.8b00913\n",
    "\n",
    "[2] Schütt, K. T., Sauceda, H. E., Kindermans, P.-J., Tkatchenko, A., and Müller, K.-R. (2018). SchNet - A deep learning architecture for molecules and materials. _J. Chem. Phys._ https://doi.org/10.1063/1.5019779"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
